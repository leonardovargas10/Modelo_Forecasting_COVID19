{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: blue; font-size: 34px; font-weight: bold;'> Projeto Proposto \n",
    "</h1>\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i> Este projeto tem o intuito de studar Modelos de Séries Temporais para previsão de informações sobre o Covid19 no Brasil. </i>       \n",
    "</p>  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Problemática </font>\n",
    "<hr style='border: 2px solid red;'>\n",
    "\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i>  Este projeto tem o intuito de studar Modelos de Séries Temporais para previsão de informações sobre o Covid19 no Brasil.\n",
    "\n",
    "\n",
    "</i> \n",
    "</p>  \n",
    "\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i> \n",
    "</i> \n",
    "</p>  \n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/unanimad/corona-virus-brazil?select=brazil_covid19_cities.csv\n",
    "\n",
    "https://www.kaggle.com/code/mauriciofigueiredo/an-lise-e-previs-o-de-s-ries-temporais-covid\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Bibliotecas Utilizadas </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bibliotecas De Manipulação de Dados e Visualização\n",
    "import pandas as pd \n",
    "import builtins as builtins\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import SparkSession, Row, functions as F \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from IPython.display import display, Image\n",
    "\n",
    "## Bibliotecas de Modelagem Matemática e Estatística\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "import scipy.stats as stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import normaltest, ttest_ind, ttest_rel, mannwhitneyu, wilcoxon, kruskal\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "# Bibliotecas de Manipulação de Tempo\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Bibiliotecas de Seleção de Modelos\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate, GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer \n",
    "from sklearn.feature_selection import RFE, VarianceThreshold\n",
    "from feature_engine.selection import DropConstantFeatures, DropCorrelatedFeatures, SmartCorrelatedSelection\n",
    "\n",
    "# Bibliotecas de Pré-Processamento e Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from category_encoders import TargetEncoder, BinaryEncoder\n",
    "import category_encoders as ce \n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Bibliotecas de Modelos de Machine Learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Bibliotecas de Métricas de Machine Learning\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Parâmetros de Otimização\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # Tira os números do formato de Notação Científica\n",
    "np.set_printoptions(suppress=True) # Tira os números do formato de Notação Científica em Numpy Arrays\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Retira Future Warnings\n",
    "\n",
    "# Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Funções </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_temporal(df, titulo, x, y):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df, color='#1FB3E5', linewidth=2)\n",
    "    plt.scatter(df.index, df, color='#1FB3E5', s=40)\n",
    "    plt.title(f\"{titulo}\", fontsize=14)  # Define o título do gráfico e o tamanho da fonte\n",
    "    plt.xlabel(f\"{x}\", fontsize=12)  # Define o rótulo do eixo x e o tamanho da fonte\n",
    "    plt.ylabel(f\"{y}\", fontsize=12)  # Define o rótulo do eixo y e o tamanho da fonte\n",
    "    plt.xticks(df.index, fontsize=10)  # Define o tamanho da fonte dos valores no eixo x\n",
    "    plt.yticks(fontsize=10)  # Define o tamanho da fonte dos valores no eixo y\n",
    "    plt.grid(True, linestyle=':', alpha=0.5)  # Adiciona linhas de grade\n",
    "    plt.tight_layout()  # Ajusta automaticamente a posição dos elementos do gráfico\n",
    "    plt.show()  # Exibe o gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ano_mes_dia(df):\n",
    "\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['year'] = df['timestamp'].dt.year\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    df['day'] = df['timestamp'].dt.day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_feature_target(target, dados):\n",
    "    x = dados.drop(target, axis = 1)\n",
    "    y = dados[[target]]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_treino_teste_temporal(data, data_teste, dados):\n",
    "    dados.sort_values(by = data, ascending = True, inplace = True)\n",
    "    df_train = dados.loc[dados[data] < data_teste]\n",
    "    df_test = dados.loc[dados[data] >= data_teste]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretiza_variavel(df, variavel_quant, variavel_qualit, bins, labels, right):\n",
    "    df[variavel_qualit] = pd.cut(\n",
    "        df[variavel_quant], \n",
    "        bins= bins, \n",
    "        labels= labels, \n",
    "        right = right\n",
    "    )\n",
    "    df.drop(variavel_quant, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(regressor, target, y_train, y_predict_train, y_test, y_predict_test, coeficiente_det_train, coeficiente_det_test):\n",
    "    y_test[target].fillna(y_train[target].median(), inplace = True)\n",
    "\n",
    "    mae_train = mean_absolute_error(y_predict_train, y_train)\n",
    "    mse_train = mean_squared_error(y_predict_train, y_train)\n",
    "    mape_train = mean_absolute_percentage_error(y_predict_train, y_train)\n",
    "    metricas_treino = pd.DataFrame({'Coeficiente de Determinação (R^2)':coeficiente_det_train, 'Erro_Medio_Absoluto':mae_train, 'Erro_Quadratico_Medio':mse_train, 'Media_Percentual_Absoluta_Erro':mape_train, 'Etapa':'treino', 'Regressor':regressor}, index = np.arange(1, 2))\n",
    "\n",
    "\n",
    "    mae_test = mean_absolute_error(y_predict_test, y_test)\n",
    "    mse_test = mean_squared_error(y_predict_test, y_test)\n",
    "    mape_test = mean_absolute_percentage_error(y_predict_test, y_test)\n",
    "    metricas_teste = pd.DataFrame({'Coeficiente de Determinação (R^2)':coeficiente_det_test, 'Erro_Medio_Absoluto':mae_test, 'Erro_Quadratico_Medio':mse_test, 'Media_Percentual_Absoluta_Erro':mape_test, 'Etapa':'teste', 'Regressor':regressor}, index = np.arange(1, 2))\n",
    "\n",
    "    metricas_finais = pd.concat([metricas_treino, metricas_teste])\n",
    "\n",
    "    return metricas_finais\n",
    "\n",
    "def metricas_modelos_juntos(lista_modelos):\n",
    "    metricas_modelos = pd.concat(lista_modelos).set_index('Regressor')\n",
    "    return metricas_modelos\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 1) Leitura do Dataset </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Descrição das Variáveis </font>\n",
    "<hr style='border: 2px solid green;'>\n",
    "\n",
    "## 1.1.1) Cases\n",
    "\n",
    "- **Date:** Anomesdia.\n",
    "- **State:** Estado.\n",
    "- **Name:** Nome do Estado.\n",
    "- **Code:** Código.\n",
    "- **Cases:** Casos.\n",
    "- **Deaths:** Mortes.\n",
    "\n",
    "## 1.2) Cities\n",
    "\n",
    "- **State Code:** Código do Estado.\n",
    "- **City Code:** Código da Cidade.\n",
    "- **City Name:** Nome da Cidade.\n",
    "- **Lat:** Latitude.\n",
    "- **Long:** Longitude.\n",
    "- **Capital:** Flag para saber se é uma capital.\n",
    "\n",
    "## 1.3) Population\n",
    "\n",
    "- **Region:** Região.\n",
    "- **State:** Nome do Estado.\n",
    "- **City:** Nome da Cidade.\n",
    "- **City Code:** Código da Cidade.\n",
    "- **Health Region Code:** Código da Região de Saúde.\n",
    "- **Health Region:** Nome da Região de Saúde.\n",
    "- **Population:** População da Cidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura das Bases de Dados\n",
    "\n",
    "df_raw_cases = pd.read_csv('./data/brazil_covid19_cities.csv')\n",
    "df_raw_population = pd.read_excel('./data/brazil_population_2019.xlsx')\n",
    "df_raw_cities = pd.read_excel('./data/brazil_cities_coordinates.xlsx')\n",
    "df_raw_cities['city_code'] = df_raw_cities['city_code'].astype(str).str[:-1].astype(int)\n",
    "# Bases Raw separadas em Base de Casos e Bases Geográficas\n",
    "\n",
    "df_cases = df_raw_cases.copy()\n",
    "df_cases['code'] = df_cases['code'].astype(int)\n",
    "df_cases['cases'] = df_cases['cases'].astype(int)\n",
    "\n",
    "df_geo = df_raw_population.merge(df_raw_cities, on = [\"state_code\", \"city_code\"], how = 'left').drop([ 'Unnamed: 8','city_name', 'health_region_code', 'health_region'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 2) Análise Exploratória </font>\n",
    "<hr style='border: 2px solid red;'>\n",
    "\n",
    "> 1. Para a análise, vamos explorar os seguintes tópicos:\n",
    "\n",
    "- Distribuição Acumulada de Casos, Mortes, Taxa de Casos/População e Taxa de Mortes/População no Total, por Estado e as Top Cidades\n",
    "- Distribuição ao longo do Tempo de Casos, Mortes, Taxa de Casos/População e Taxa de Mortes/População no Total, por Estado e as Top Cidades\n",
    "- Mapa do Brasil colorido de acordo com a Taxa de Casos/População e Mortes/População"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.1) Distribuição Acumulada </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.2) Distribuição ao Longo do Tempo </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='green' style='font-size: 30px;'> 1.3) Mapa do Brasil com a Taxa de Casos/População e Taxa de Mortes/População </font>\n",
    "<hr style='border: 2px solid green;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw_groupped = df_raw.groupby(['Date', 'Country/Region']).agg({\n",
    "#     \"Lat\": \"max\", \n",
    "#     \"Long\": \"max\", \n",
    "#     \"Confirmed\": \"sum\", \n",
    "#     \"Recovered\": \"sum\", \n",
    "#     \"Deaths\": \"sum\"\n",
    "# }).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16,8))\n",
    "# ax = plt.subplot(1,2,1)\n",
    "# ax.set_title('Casos Acumulados', fontsize=18, loc='left')\n",
    "# plt.plot(df_brazil['Brazil'], label='Brazil')\n",
    "# plt.plot(df_conf_w['Argentina'], label='Argentina')\n",
    "# plt.plot(df_conf_w['Uruguay'], label='Uruguay')\n",
    "# plt.xlabel(\"Dia\")\n",
    "# plt.ylabel(\"Casos\")\n",
    "# plt.legend();\n",
    "# ax = plt.subplot(1,2,2)\n",
    "# ax.set_title('Óbitos Acumulados', fontsize=18, loc='left')\n",
    "# plt.plot(df_brazil['Brazil'], label='Brazil')\n",
    "# plt.plot(df_deaths_w['Argentina'], label='Argentina')\n",
    "# plt.plot(df_deaths_w['Uruguay'], label='Uruguay')\n",
    "# plt.xlabel(\"Dia\")\n",
    "# plt.ylabel(\"Óbitos\")\n",
    "# plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
