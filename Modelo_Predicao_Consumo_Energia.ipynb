{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='color: blue; font-size: 34px; font-weight: bold;'> Projeto Proposto \n",
    "</h1>\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i> Este projeto baseia-se na criação de um Modelo de Regressão para Previsão do Consumo de Energia. </i>       \n",
    "</p>  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Problemática </font>\n",
    "<hr style='border: 2px solid red;'>\n",
    "\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i>  Este projeto tem o intuito de ser um Modelo de Machine Learning para prever o consumo de eletricidade com base em metadados de construção, utilizando histórico e dados meteorológicos. O conjunto de dados inclui leituras de medidores por hora de 100 edifícios em vários locais diferentes ao redor do mundo.\n",
    "\n",
    "\n",
    "</i> \n",
    "</p>  \n",
    "\n",
    "<p style='font-size: 18px; line-height: 2; margin: 0px 0px; text-align: justify; text-indent: 0px;'>    \n",
    "<i> \n",
    "</i> \n",
    "</p>  \n",
    "\n",
    "\n",
    "https://www.kaggle.com/competitions/predicting-electricity-consumption/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Bibliotecas Utilizadas </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bibliotecas De Manipulação de Dados e Visualização\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from IPython.display import display, Image\n",
    "\n",
    "## Bibliotecas de Modelagem Matemática e Estatística\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "import scipy.stats as stats\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import normaltest\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "\n",
    "\n",
    "# Bibliotecas de Manipulação de Tempo\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Bibiliotecas de Seleção de Modelos\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer \n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Bibliotecas de Pré-Processamento e Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from category_encoders import TargetEncoder, BinaryEncoder\n",
    "import category_encoders as ce \n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "# Bibliotecas de Modelos de Machine Learning\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Bibliotecas de Métricas de Machine Learning\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Parâmetros de Otimização\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = '14'\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # Tira os números do formato de Notação Científica\n",
    "np.set_printoptions(suppress=True) # Tira os números do formato de Notação Científica em Numpy Arrays\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Retira Future Warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> Funções </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Visualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Barras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_barras(lista_variaveis, hue, df, linhas, colunas, titulo):\n",
    "    if hue != False:\n",
    "        if (linhas == 1) and (colunas == 1):\n",
    "            k = 0\n",
    "            ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', hue = hue)\n",
    "            ax.set_title(f'{titulo}')\n",
    "            ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "            ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "            total = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                total.append(height)\n",
    "            total = sum(total)\n",
    "            \n",
    "            sizes = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                sizes.append(height)\n",
    "                ax.text(bar.get_x() + bar.get_width(),\n",
    "                        height,\n",
    "                        f'{round((height/total)*100, 2)}%',\n",
    "                        ha = 'center',\n",
    "                        fontsize = 12\n",
    "                )\n",
    "            ax.set_ylim(0, max(sizes)*1.1)\n",
    "            plt.show()\n",
    "        elif linhas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(20, 10), sharey=True)\n",
    "            fig.suptitle(f'titulo')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[j], hue = hue)\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width(),\n",
    "                                height,\n",
    "                                f'{round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        elif colunas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(20, 10), sharey=True)\n",
    "            fig.suptitle(f'titulo')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i], hue = hue)\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width(),\n",
    "                                height,\n",
    "                                f'{round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        else: \n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(20, 10), sharey=True)\n",
    "            fig.suptitle(f'titulo')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i, j], hue = hue)\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width(),\n",
    "                                height,\n",
    "                                f'{round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "    else:\n",
    "        if (linhas == 1) and (colunas == 1):\n",
    "            k = 0\n",
    "            ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', color='#1FB3E5')\n",
    "            ax.set_title(f'{titulo}')\n",
    "            ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "            ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "            total = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                total.append(height)\n",
    "            total = sum(total)\n",
    "            \n",
    "            sizes = []\n",
    "            for bar in ax.patches:\n",
    "                height = bar.get_height()\n",
    "                sizes.append(height)\n",
    "                ax.text(bar.get_x() + bar.get_width(),\n",
    "                        height,\n",
    "                        f'{round((height/total)*100, 2)}%',\n",
    "                        ha = 'center',\n",
    "                        fontsize = 12\n",
    "                )\n",
    "            ax.set_ylim(0, max(sizes)*1.1)\n",
    "            plt.show()\n",
    "\n",
    "        elif linhas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(20, 10), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[j], color='#1FB3E5')\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width(),\n",
    "                                height,\n",
    "                                f'{round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        elif colunas == 1:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(20, 10), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i], color='#1FB3E5')\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width(),\n",
    "                                height,\n",
    "                                f'{round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, max(sizes)*1.1)\n",
    "                    k = k + 1\n",
    "        else:\n",
    "            fig, axis = plt.subplots(linhas, colunas, figsize=(20, 10), sharey=True)\n",
    "            fig.suptitle(f'{titulo}')\n",
    "            k = 0\n",
    "            for i in np.arange(linhas):\n",
    "                for j in np.arange(colunas):\n",
    "                    ax = sns.countplot(x = lista_variaveis[k], data = df, orient = 'h', ax = axis[i, j], color='#1FB3E5')\n",
    "                    ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                    ax.set_ylabel(f'Quantidade', fontsize = 14)\n",
    "                    total = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        total.append(height)\n",
    "                    total = sum(total)\n",
    "                    \n",
    "                    sizes = []\n",
    "                    for bar in ax.patches:\n",
    "                        height = bar.get_height()\n",
    "                        sizes.append(height)\n",
    "                        ax.text(bar.get_x() + bar.get_width(),\n",
    "                                height,\n",
    "                                f'{round((height/total)*100, 2)}%',\n",
    "                                ha = 'center',\n",
    "                                fontsize = 12\n",
    "                        )\n",
    "                    ax.set_ylim(0, max(sizes)*1.1)\n",
    "                    k = k + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Histogramas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_histograma(lista_variaveis, df, linhas, colunas, titulo):\n",
    "    if (linhas == 1) and (colunas == 1): \n",
    "        k = 0\n",
    "        mediana = df[lista_variaveis[k]].median()\n",
    "        media = round(df[lista_variaveis[k]].mean(), 2)\n",
    "        plt.figure(figsize = (14, 4))\n",
    "        ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', bins = 30)\n",
    "        ax.set_title(f'{titulo}')\n",
    "        ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "        ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "        ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "        ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "        plt.ticklabel_format(style='plain')\n",
    "        plt.legend(loc = 'best')\n",
    "        plt.show()\n",
    "    elif linhas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 4), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                mediana = df[lista_variaveis[k]].median()\n",
    "                media = round(df[lista_variaveis[k]].mean(), 2)\n",
    "                ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[j], bins = 30)\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "                ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "                ax.ticklabel_format(style='plain')\n",
    "                ax.legend(loc = 'best')\n",
    "                k = k + 1\n",
    "    elif colunas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 4), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                mediana = df[lista_variaveis[k]].median()\n",
    "                media = round(df[lista_variaveis[k]].mean(), 2)\n",
    "                ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i], bins = 30)\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "                ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "                ax.ticklabel_format(style='plain')\n",
    "                ax.legend(loc = 'best')\n",
    "                k = k + 1\n",
    "    else:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 4), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                mediana = df[lista_variaveis[k]].median()\n",
    "                media = round(df[lista_variaveis[k]].mean(), 2)\n",
    "                ax = sns.histplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i, j], bins = 30)\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                ax.axvline(x = mediana, ymax = 0.75 ,color = '#231F20', linestyle = '-', label = f'mediana = {mediana}')\n",
    "                ax.axvline(x = media, ymax = 0.75,color = '#231F20', linestyle = '--', label = f'media = {media}')\n",
    "                ax.ticklabel_format(style='plain')\n",
    "                ax.legend(loc = 'best')\n",
    "                k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_boxplot(lista_variaveis, df, linhas, colunas, titulo):\n",
    "    if (linhas == 1) and (colunas == 1): \n",
    "        k = 0\n",
    "        plt.figure(figsize = (14, 4))\n",
    "        ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', orient = 'h')\n",
    "        ax.set_title(f'{titulo}')\n",
    "        ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "        ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "        plt.show()\n",
    "    elif linhas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 4), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[j], orient = 'h')\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                k = k + 1\n",
    "    elif colunas == 1:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 4), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i], orient = 'h')\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                k = k + 1\n",
    "    else:\n",
    "        fig, axis = plt.subplots(linhas, colunas, figsize = (14, 4), sharey = True)\n",
    "        k = 0\n",
    "        for i in np.arange(linhas):\n",
    "            for j in np.arange(colunas):\n",
    "                ax = sns.boxplot(x = lista_variaveis[k], data = df, color = '#1FB3E5', ax = axis[i, j], orient = 'h')\n",
    "                ax.set_title(f'{titulo}')\n",
    "                ax.set_xlabel(f'{lista_variaveis[k]}', fontsize = 14)\n",
    "                ax.set_ylabel(f'Frequência', fontsize = 14)\n",
    "                k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plota Dispersão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_dispersao(x, y, dados):\n",
    "    plt.figure(figsize = (14, 4))\n",
    "    plt.scatter(data = dados, x = x, y = y, color='#1FB3E5', s = 10, alpha = 0.50, marker = '.')\n",
    "    plt.title(f'Gráfico de Dispersão entre {x} e {y}', fontsize = 14)\n",
    "    plt.xlabel(f'{x}', fontsize = 14)\n",
    "    plt.ylabel(f'{y}', fontsize = 14)\n",
    "    plt.grid(False)\n",
    "    plt.box(False)\n",
    "    plt.ticklabel_format(style='plain')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Estatística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analisa Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_correlacao(metodo, df):\n",
    "    plt.figure(figsize = (14, 7))\n",
    "    sns.heatmap(df.corr(method = metodo), vmin = -1, vmax = 1, cmap = 'magma', annot = True)\n",
    "    plt.title(f\"Analisando Correlação de {metodo}\")\n",
    "    plt.grid(False)\n",
    "    plt.box(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analisa Normalidade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_normalidade(amostra1, amostra2, variavel):\n",
    "\n",
    "    normaltest_amostra_1 = normaltest(amostra1[variavel])\n",
    "    normaltest_amostra_2 = normaltest(amostra2[variavel])\n",
    "\n",
    "    if (normaltest_amostra_1[1] < 0.05 ) and (normaltest_amostra_2[1] < 0.05):\n",
    "        print(f'Pelo Teste de Hipótese, A Hipótese Nula de que a variável \"{variavel}\" segue uma Distribuição Normal é REJEITADA!')\n",
    "    else:\n",
    "        print(f'Pelo Teste de Hipótese, A Hipótese Nula de  que a variável \"{variavel}\" segue uma Distribuição Normal é ACEITA')\n",
    "\n",
    "    ax1 = plt.subplot(121)\n",
    "    stats.probplot(amostra1[variavel], dist = 'norm', plot = plt)\n",
    "    plt.title(f'Amostra 1', fontsize = 14)\n",
    "    plt.grid(False)\n",
    "    plt.box(False)\n",
    "    plt.tight_layout()\n",
    "    ax1 = plt.subplot(122)\n",
    "    stats.probplot(amostra2[variavel], dist = 'norm', plot = plt)\n",
    "    plt.title(f'Amostra 2', fontsize = 14)\n",
    "    plt.grid(False)\n",
    "    plt.box(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Teste de Hipótese para Duas Amostras Independentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste_hipotese_duas_amostras_independentes(parametrico, amostra1, amostra2, variavel):\n",
    "\n",
    "    media_amostra_1 = amostra1[variavel].mean()\n",
    "    media_amostra_2 = amostra2[variavel].mean()\n",
    "    mediana_amostra_1 = amostra1[variavel].median()\n",
    "    mediana_amostra_2 = amostra2[variavel].median()\n",
    "\n",
    "    if parametrico == True: \n",
    "        print(f'Média Amostra 1: {media_amostra_1}')\n",
    "        print(f'Média Amostra 2: {media_amostra_2}')\n",
    "        stat, p_value = ztest(amostra1[variavel], amostra2[variavel]) \n",
    "        if p_value > 0.05:\n",
    "            print(f'Pelo Teste de Hipótese Z, não há diferença significativa entre as médias da Amostra 1 e Amostra 2')\n",
    "        else:\n",
    "            print(f'Pelo Teste de Hipótese Z, há diferença significativa entre as médias da Amostra 1 e Amostra 2')\n",
    "    else:\n",
    "        print(f'Mediana Amostra 1: {mediana_amostra_1}')\n",
    "        print(f'Mediana Amostra 2: {mediana_amostra_2}')\n",
    "        stat, p_value = stats.mannwhitneyu(amostra1[variavel], amostra2[variavel]) \n",
    "        if p_value > 0.05:\n",
    "            print(f'Pelo Teste de Hipótese de Mann Whitney, não há diferença significativa entre as medianas da Amostra 1 e Amostra 2')\n",
    "        else:\n",
    "            print(f'Pelo Teste de Hipótese de Mann Whitney, há diferença significativa entre as medianas da Amostra 1 e Amostra 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Pré-Processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Separa entre Features e Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_feature_target(target, dados):\n",
    "    x = dados.drop(target, axis = 1)\n",
    "    y = dados[[target]]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separa entre Treino e Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_treino_teste_temporal(data, data_teste, dados):\n",
    "    dados.sort_values(by = data, ascending = True, inplace = True)\n",
    "    df_train = dados.loc[dados[data] < data_teste]\n",
    "    df_test = dados.loc[dados[data] >= data_teste]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Métricas ou Avaliação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricas(regressor, target, y_train, y_predict_train, y_test, y_predict_test, coeficiente_det_train, coeficiente_det_test):\n",
    "    y_test[target].fillna(y_train[target].median(), inplace = True)\n",
    "\n",
    "    mae_train = mean_absolute_error(y_predict_train, y_train)\n",
    "    mse_train = mean_squared_error(y_predict_train, y_train)\n",
    "    mape_train = mean_absolute_percentage_error(y_predict_train, y_train)\n",
    "    metricas_treino = pd.DataFrame({'Coeficiente de Determinação (R^2)':coeficiente_det_train, 'Erro_Medio_Absoluto':mae_train, 'Erro_Quadratico_Medio':mse_train, 'Media_Percentual_Absoluta_Erro':mape_train, 'Etapa':'treino', 'Regressor':regressor}, index = np.arange(1, 2))\n",
    "\n",
    "\n",
    "    mae_test = mean_absolute_error(y_predict_test, y_test)\n",
    "    mse_test = mean_squared_error(y_predict_test, y_test)\n",
    "    mape_test = mean_absolute_percentage_error(y_predict_test, y_test)\n",
    "    metricas_teste = pd.DataFrame({'Coeficiente de Determinação (R^2)':coeficiente_det_test, 'Erro_Medio_Absoluto':mae_test, 'Erro_Quadratico_Medio':mse_test, 'Media_Percentual_Absoluta_Erro':mape_test, 'Etapa':'teste', 'Regressor':regressor}, index = np.arange(1, 2))\n",
    "\n",
    "    metricas_finais = pd.concat([metricas_treino, metricas_teste])\n",
    "\n",
    "    return metricas_finais\n",
    "\n",
    "def metricas_modelos_juntos(lista_modelos):\n",
    "    metricas_modelos = pd.concat(lista_modelos).set_index('Regressor')\n",
    "    return metricas_modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validação Cruzada "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao_cruzada(target_type, x_train, y_train, n_splits, regressor):\n",
    "    categoricas = [column for column in x_train.columns if x_train[column].dtype.name == 'object']\n",
    "    numericas = [column for column in x_train.columns if (x_train[column].dtype.name == 'int64') or (x_train[column].dtype.name == 'float64')]\n",
    "\n",
    "    pipeline_categoricas = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value = 'missing')),\n",
    "        ('encoder',  OneHotEncoder(handle_unknown='ignore', sparse = False))\n",
    "    ])\n",
    "\n",
    "    pipeline_numericas = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    pre_processamento = ColumnTransformer([\n",
    "    ('cat', pipeline_categoricas, categoricas),\n",
    "    ('num', pipeline_numericas, numericas)\n",
    "    ])\n",
    "\n",
    "    if target_type == 'categorico':\n",
    "        y_train.fillna(y_train.mode(), inplace = True)\n",
    "        y_test.fillna(y_train.mode(), inplace = True)\n",
    "\n",
    "    else:\n",
    "        y_train.fillna(y_train.median(), inplace = True)\n",
    "        y_test.fillna(y_train.median(), inplace = True)\n",
    "\n",
    "    kfold = KFold(n_splits = n_splits, shuffle = True, random_state = 42)\n",
    "\n",
    "    if regressor == 'Regressão Linear Múltipla':\n",
    "        model = make_pipeline(pre_processamento, LinearRegression())\n",
    "        coef_det = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'r2').mean()\n",
    "        mae = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'neg_mean_absolute_error').mean()\n",
    "        mse = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'neg_mean_squared_error').mean()\n",
    "        mape = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'neg_mean_absolute_percentage_error').mean()\n",
    "\n",
    "    elif regressor == 'Random Forest':\n",
    "        model = make_pipeline(pre_processamento, RandomForestRegressor(n_estimators = 100, max_depth = 9, criterion = 'squared_error',random_state = 42))\n",
    "        coef_det = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'r2').mean()\n",
    "        mae = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'neg_mean_absolute_error').mean()\n",
    "        mse = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'neg_mean_squared_error').mean()\n",
    "        mape = cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'neg_mean_absolute_percentage_error').mean()\n",
    "    \n",
    "    else:\n",
    "        print('Utiliz Regressão Linear Múltipla ou Random Forest como opções de Regressores!')\n",
    "\n",
    "\n",
    "    metricas_finais = pd.DataFrame({'Coeficiente de Determinação (R^2)':coef_det, 'Erro_Medio_Absoluto':mae*-1, 'Erro_Quadratico_Medio':mse*-1, 'Media_Percentual_Absoluta_Erro':mape*-1, 'Etapa':'validacao_cruzada', 'Regressor':regressor}, index = np.arange(1, 2))\n",
    "\n",
    "    return metricas_finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressao_linear_multipla(target_type, x_train, y_train, x_test, y_test, otimizacao, numero_features):\n",
    "\n",
    "    categoricas = [column for column in x_train.columns if x_train[column].dtype.name == 'object']\n",
    "    numericas = [column for column in x_train.columns if (x_train[column].dtype.name == 'int64') or (x_train[column].dtype.name == 'float64')]\n",
    "\n",
    "    pipeline_categoricas = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value = 'missing')),\n",
    "        ('encoder',  OneHotEncoder(handle_unknown='ignore', sparse = False))\n",
    "    ])\n",
    "\n",
    "    pipeline_numericas = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    pre_processamento = ColumnTransformer([\n",
    "    ('cat', pipeline_categoricas, categoricas),\n",
    "    ('num', pipeline_numericas, numericas)\n",
    "    ])\n",
    "\n",
    "    if target_type == 'categorico':\n",
    "        y_train.fillna(y_train.mode(), inplace = True)\n",
    "    else:\n",
    "        y_train.fillna(y_train.median(), inplace = True)\n",
    "        y_test.fillna(y_train.median(), inplace = True)\n",
    "\n",
    "    if otimizacao == True:\n",
    "        model = make_pipeline(pre_processamento, RFE(LinearRegression(), step = 1, n_features_to_select = numero_features))\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_predict_train = model.predict(x_train)\n",
    "        y_predict_test = model.predict(x_test)\n",
    "\n",
    "        coef_det_train = round(model.score(x_train, y_train), 2)\n",
    "        coef_det_test = round(model.score(x_test, y_test), 2)\n",
    "\n",
    "    else:\n",
    "        model = make_pipeline(pre_processamento, LinearRegression())\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_predict_train = model.predict(x_train)\n",
    "        y_predict_test = model.predict(x_test)\n",
    "\n",
    "        coef_det_train = round(model.score(x_train, y_train), 2)\n",
    "        coef_det_test = round(model.score(x_test, y_test), 2)\n",
    "\n",
    "    \n",
    "    return y_predict_train, y_predict_test, coef_det_train, coef_det_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressao_random_forest(target_type, x_train, y_train, x_test, y_test, otimizacao, numero_features):\n",
    "\n",
    "    categoricas = [column for column in x_train.columns if x_train[column].dtype.name == 'object']\n",
    "    numericas = [column for column in x_train.columns if (x_train[column].dtype.name == 'int64') or (x_train[column].dtype.name == 'float64')]\n",
    "\n",
    "    pipeline_categoricas = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value = 'missing')),\n",
    "        ('encoder',  OneHotEncoder(handle_unknown='ignore', sparse = False))\n",
    "    ])\n",
    "\n",
    "    pipeline_numericas = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    pre_processamento = ColumnTransformer([\n",
    "    ('cat', pipeline_categoricas, categoricas),\n",
    "    ('num', pipeline_numericas, numericas)\n",
    "    ])\n",
    "\n",
    "    if target_type == 'categorico':\n",
    "        y_train.fillna(y_train.mode(), inplace = True)\n",
    "        y_test.fillna(y_train.mode(), inplace = True)\n",
    "\n",
    "    else:\n",
    "        y_train.fillna(y_train.median(), inplace = True)\n",
    "        y_test.fillna(y_train.median(), inplace = True)\n",
    "\n",
    "    if otimizacao == True:\n",
    "        model = make_pipeline(pre_processamento, RFE(RandomForestRegressor(n_estimators = 100, max_depth = 9, criterion = 'squared_error',random_state = 42), step = 1, n_features_to_select = numero_features))\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_predict_train = model.predict(x_train)\n",
    "        y_predict_test = model.predict(x_test)\n",
    "\n",
    "        coef_det_train = round(model.score(x_train, y_train), 2)\n",
    "        coef_det_test = round(model.score(x_test, y_test), 2)\n",
    "\n",
    "    else:\n",
    "        model = make_pipeline(pre_processamento, RandomForestRegressor(n_estimators = 100, max_depth = 9, criterion = 'squared_error',random_state = 42))\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        y_predict_train = model.predict(x_train)\n",
    "        y_predict_test = model.predict(x_test)\n",
    "\n",
    "        coef_det_train = round(model.score(x_train, y_train), 2)\n",
    "        coef_det_test = round(model.score(x_test, y_test), 2)\n",
    "\n",
    "    \n",
    "    return y_predict_train, y_predict_test, coef_det_train, coef_det_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 1) Entendimento da Base de Dados </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../04_modelo_predicao_consumo_energia/data/train.csv')\n",
    "test = pd.read_csv('../04_modelo_predicao_consumo_energia/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 2.0 Análise Exploratória  - Foco em Análises Univariadas </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 3.0 Análise Exploratória - Foco em Análises Bivariadas </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 4.0 Feature Engineer </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 5.0 Aplicação de Modelos de Machine Learning </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red' style='font-size: 40px;'> 6.0 Consolidação dos Resultados </font>\n",
    "<hr style='border: 2px solid red;'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
